'use strict';

// NOTE: indices must be in descending order

const assert = require('assert');
const { leftShift, and, or } = require('bitwise-buffer');

const { hashNode, to32ByteBuffer, to32ByteBoolBuffer } = require('./utils');

// This is the MultiIndexedProof.generate algorithm, however, since indices will not be used to
// compute the root at verify-time, a set fo flags need to be generated to indicate, for each
// hash performed at verify-time, whether a previously computed hash will be needed (True), or
// a decommitment will be needed. Since this method only works with hash functions that sort the
// hashed material, there is no need to provide instructions on hashing order. However, such a
// proof would also be possible, with a separate set of flags to instruct the hashing order.
// See MultiIndexedProof.generate for relevant inline comments.
const generateBooleans = ({ tree, indices }, options = {}) => {
  const { sortedHash = true } = options;
  const known = Array(tree.length).fill(false);
  const relevant = Array(tree.length).fill(false);
  const decommitments = [];
  const flags = [];
  const orders = [];
  const skips = [];
  const leafCount = tree.length >>> 1;

  for (let i = 0; i < indices.length; i++) {
    assert(i === 0 || indices[i - 1] > indices[i], 'Indices must be in descending order.');
    known[leafCount + indices[i]] = true;

    // The parent of this node is relevant, as there will be a hash computed at verify-time.
    relevant[(leafCount + indices[i]) >>> 1] = true;
  }

  for (let i = leafCount - 1; i > 0; i--) {
    const leftChildIndex = i << 1;
    const left = known[leftChildIndex];
    const right = known[leftChildIndex + 1];
    const sibling = tree[leftChildIndex + left];

    if (left ^ right) decommitments.push(sibling);

    // Since there will be a hash computed at verify-time, push the flag on wether this hash
    // will require a decommitment (False) or a previously computed hash (True). Also, if the
    // sibling of this child does not exist, the sibling must be to the "right" of the
    // "right-most" leaf, so the hash can be skipped in favor of just using the child itself.
    // Further, the parent of this node it itself relevant, in a subsequent iteration.
    if (relevant[i]) {
      flags.push(left === right);
      skips.push(!sibling);
      orders.push(left);
      relevant[i >>> 1] = true;
    }

    known[i] = left || right;
  }

  return {
    decommitments: decommitments.filter((d) => d).map(Buffer.from),
    flags,
    skips,
    orders: !sortedHash ? orders : undefined,
  };
};

// Convert the flags, skips, and orders generated by generateBooleans into a 32-byte bit-set
const generateBits = ({ tree, indices }, options = {}) => {
  const { decommitments, flags, orders, skips } = generateBooleans({ tree, indices }, options);

  assert(flags.length <= 255, 'Proof too large for bit flags.');

  const stopMask = leftShift(to32ByteBuffer(1), flags.length);
  const proof = orders ? [to32ByteBoolBuffer(orders)].concat(decommitments) : decommitments;
  const flagsAsBits = or(to32ByteBoolBuffer(flags), stopMask);
  const skipsAsBits = or(to32ByteBoolBuffer(skips), stopMask);

  return { compactProof: [flagsAsBits, skipsAsBits].concat(proof) };
};

const generate = (parameters, options = {}) => {
  return options.compact ? generateBits(parameters, options) : generateBooleans(parameters, options);
};

// This is the MultiIndexedProof.getRoot algorithm, slightly simplified to take into account that
// this is to be used with a hash function that sorts the material it hashes, and thus this uses flags
// to determine hashing content, instead of the indices. Further, this implements skipping hashing for
// nodes without siblings to the "right", in the case of unbalanced trees.
// See MultiIndexedProof.getRoot for relevant inline comments.
const getRootBooleans = ({ leafs, flags, skips, orders, decommitments }, options = {}) => {
  const { hashFunction = hashNode } = options;
  const hashCount = flags.length;
  const leafCount = leafs.length;
  const hashes = Array(leafCount).fill(null);

  let readIndex = 0;
  let writeIndex = 0;
  let decommitmentIndex = 0;
  let useLeafs = true;

  for (let i = 0; i < hashCount; i++) {
    if (skips[i]) {
      hashes[writeIndex++] = useLeafs ? leafs[readIndex++] : hashes[readIndex++];

      if (useLeafs && readIndex === leafCount) useLeafs = false;

      readIndex %= leafCount;
      writeIndex %= leafCount;
      continue;
    }

    const right = flags[i] ? (useLeafs ? leafs[readIndex++] : hashes[readIndex++]) : decommitments[decommitmentIndex++];
    readIndex %= leafCount;
    const left = useLeafs ? leafs[readIndex++] : hashes[readIndex++];
    hashes[writeIndex++] = orders?.[i] ? hashFunction(left, right) : hashFunction(right, left);

    if (useLeafs && readIndex === leafCount) useLeafs = false;

    readIndex %= leafCount;
    writeIndex %= leafCount;
  }

  const rootIndex = (writeIndex === 0 ? leafCount : writeIndex) - 1;

  return { root: Buffer.from(useLeafs ? leafs[0] : hashes[rootIndex]) };
};

// This is identical to the above getRootBooleans algorithm, differing only in that the
// the flag and skip bit-set is shifted and checked, rather than boolean arrays.
// See getRootBooleans for relevant inline comments.
const getRootBits = ({ leafs, compactProof }, options = {}) => {
  const { hashFunction = hashNode, sortedHash = true } = options;
  const flags = compactProof[0];
  const skips = compactProof[1];
  const orders = sortedHash ? undefined : compactProof[2];
  const decommitments = compactProof.slice(sortedHash ? 2 : 3);
  const leafCount = leafs.length;
  const hashes = Array(leafCount).fill(null);

  let readIndex = 0;
  let writeIndex = 0;
  let decommitmentIndex = 0;
  let useLeafs = true;
  let bitCheck = Buffer.from('0000000000000000000000000000000000000000000000000000000000000001', 'hex');

  while (true) {
    const flag = and(flags, bitCheck).equals(bitCheck);

    if (and(skips, bitCheck).equals(bitCheck)) {
      if (flag) {
        const rootIndex = (writeIndex === 0 ? leafCount : writeIndex) - 1;

        return { root: Buffer.from(useLeafs ? leafs[0] : hashes[rootIndex]) };
      }

      hashes[writeIndex++] = useLeafs ? leafs[readIndex++] : hashes[readIndex++];

      if (useLeafs && readIndex === leafCount) useLeafs = false;

      readIndex %= leafCount;
      writeIndex %= leafCount;
      bitCheck = leftShift(bitCheck, 1);
      continue;
    }

    const right = flag ? (useLeafs ? leafs[readIndex++] : hashes[readIndex++]) : decommitments[decommitmentIndex++];
    readIndex %= leafCount;
    const left = useLeafs ? leafs[readIndex++] : hashes[readIndex++];

    const order = orders && and(orders, bitCheck).equals(bitCheck);
    hashes[writeIndex++] = order ? hashFunction(left, right) : hashFunction(right, left);

    if (useLeafs && readIndex === leafCount) useLeafs = false;

    readIndex %= leafCount;
    writeIndex %= leafCount;
    bitCheck = leftShift(bitCheck, 1);
  }
};

const getRoot = (parameters, options = {}) => {
  return parameters.compactProof ? getRootBits(parameters, options) : getRootBooleans(parameters, options);
};

// This is identical to the above getRootBooleans algorithm, differing only in that the
// new root (due to the updated leafs), is computed along the way.
// See getRootBooleans for relevant inline comments.
const getNewRootBooleans = ({ leafs, newLeafs, flags, skips, orders, decommitments }, options = {}) => {
  const { hashFunction = hashNode } = options;
  const hashCount = flags.length;
  const leafCount = leafs.length;
  const hashes = Array(leafCount).fill(null);
  const newHashes = Array(leafCount).fill(null);

  let readIndex = 0;
  let writeIndex = 0;
  let decommitmentIndex = 0;
  let useLeafs = true;

  for (let i = 0; i < hashCount; i++) {
    if (skips[i]) {
      hashes[writeIndex] = useLeafs ? leafs[readIndex] : hashes[readIndex];
      newHashes[writeIndex++] = useLeafs ? newLeafs[readIndex++] : newHashes[readIndex++];

      if (useLeafs && readIndex === leafCount) useLeafs = false;

      readIndex %= leafCount;
      writeIndex %= leafCount;
      continue;
    }

    const right = flags[i] ? (useLeafs ? leafs[readIndex] : hashes[readIndex]) : decommitments[decommitmentIndex];
    const newRight = flags[i]
      ? useLeafs
        ? newLeafs[readIndex++]
        : newHashes[readIndex++]
      : decommitments[decommitmentIndex++];
    readIndex %= leafCount;

    const left = useLeafs ? leafs[readIndex] : hashes[readIndex];
    const newLeft = useLeafs ? newLeafs[readIndex++] : newHashes[readIndex++];
    hashes[writeIndex] = orders?.[i] ? hashFunction(left, right) : hashFunction(right, left);
    newHashes[writeIndex++] = orders?.[i] ? hashFunction(newLeft, newRight) : hashFunction(newRight, newLeft);

    if (useLeafs && readIndex === leafCount) useLeafs = false;

    readIndex %= leafCount;
    writeIndex %= leafCount;
  }

  const rootIndex = (writeIndex === 0 ? leafCount : writeIndex) - 1;

  return {
    root: Buffer.from(useLeafs ? leafs[0] : hashes[rootIndex]),
    newRoot: Buffer.from(useLeafs ? newLeafs[0] : newHashes[rootIndex]),
  };
};

// This is identical to the above getRootBits algorithm, differing only in that the
// new root (due to the updated leafs), is computed along the way.
// See getRootBits for relevant inline comments.
const getNewRootBits = ({ leafs, newLeafs, compactProof }, options = {}) => {
  const { hashFunction = hashNode, sortedHash = true } = options;
  const flags = compactProof[0];
  const skips = compactProof[1];
  const orders = sortedHash ? undefined : compactProof[2];
  const decommitments = compactProof.slice(sortedHash ? 2 : 3);
  const leafCount = leafs.length;
  const hashes = Array(leafCount).fill(null);
  const newHashes = Array(leafCount).fill(null);

  let readIndex = 0;
  let writeIndex = 0;
  let decommitmentIndex = 0;
  let useLeafs = true;
  let bitCheck = Buffer.from('0000000000000000000000000000000000000000000000000000000000000001', 'hex');

  while (true) {
    const flag = and(flags, bitCheck).equals(bitCheck);

    if (and(skips, bitCheck).equals(bitCheck)) {
      if (flag) {
        const rootIndex = (writeIndex === 0 ? leafCount : writeIndex) - 1;

        return {
          root: Buffer.from(useLeafs ? leafs[0] : hashes[rootIndex]),
          newRoot: Buffer.from(useLeafs ? newLeafs[0] : newHashes[rootIndex]),
        };
      }

      hashes[writeIndex] = useLeafs ? leafs[readIndex] : hashes[readIndex];
      newHashes[writeIndex++] = useLeafs ? newLeafs[readIndex++] : newHashes[readIndex++];

      if (useLeafs && readIndex === leafCount) useLeafs = false;

      readIndex %= leafCount;
      writeIndex %= leafCount;
      bitCheck = leftShift(bitCheck, 1);
      continue;
    }

    const right = flag ? (useLeafs ? leafs[readIndex] : hashes[readIndex]) : decommitments[decommitmentIndex];
    const newRight = flag
      ? useLeafs
        ? newLeafs[readIndex++]
        : newHashes[readIndex++]
      : decommitments[decommitmentIndex++];
    readIndex %= leafCount;

    const left = useLeafs ? leafs[readIndex] : hashes[readIndex];
    const newLeft = useLeafs ? newLeafs[readIndex++] : newHashes[readIndex++];

    const order = orders && and(orders, bitCheck).equals(bitCheck);
    hashes[writeIndex] = order ? hashFunction(left, right) : hashFunction(right, left);
    newHashes[writeIndex++] = order ? hashFunction(newLeft, newRight) : hashFunction(newRight, newLeft);

    if (useLeafs && readIndex === leafCount) useLeafs = false;

    readIndex %= leafCount;
    writeIndex %= leafCount;
    bitCheck = leftShift(bitCheck, 1);
  }
};

const getNewRoot = (parameters, options = {}) => {
  return parameters.compactProof ? getNewRootBits(parameters, options) : getNewRootBooleans(parameters, options);
};

module.exports = { generate, getRoot, getNewRoot };
