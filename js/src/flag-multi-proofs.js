'use strict';

// NOTE: indices must be in ascending order

const assert = require('assert');
const { leftShift, and, or } = require('bitwise-buffer');

const { hashNode, to32ByteBuffer, to32ByteBoolBuffer } = require('./utils');

// This is the MultiIndexedProof.generate algorithm, however, since indices will not be used to
// compute the root at verify-time, a set fo flags need to be generated to indicate, for each
// hash performed at verify-time, whether a previously computed hash will be needed (True), or
// a decommitment will be needed. Since this method only works with hash functions that sort the
// hashed material, there is no need to provide instructions on hashing order. However, such a
// proof would also be possible, with a separate set of flags to instruct the hashing order.
// See MultiIndexedProof.generate for relevant inline comments.
const generateBooleans = ({ tree, indices }, options = {}) => {
  const { sortedHash = true } = options;
  const known = Array(tree.length).fill(false);
  const relevant = Array(tree.length).fill(false);
  const decommitments = [];
  const flags = [];
  const orders = [];
  const skips = [];
  const leafCount = tree.length >>> 1;

  for (let i = 0; i < indices.length; i++) {
    assert(i === 0 || indices[i - 1] < indices[i], 'Indices must be in ascending order.');
    known[leafCount + indices[i]] = true;

    // The parent of this node is relevant, as there will be a hash computed at verify-time.
    relevant[(leafCount + indices[i]) >>> 1] = true;
  }

  for (let i = leafCount - 1; i > 0; i--) {
    const leftChildIndex = i << 1;
    const left = known[leftChildIndex];
    const right = known[leftChildIndex + 1];
    const sibling = tree[leftChildIndex + left];

    if (left ^ right) decommitments.push(sibling);

    // Since there will be a hash computed at verify-time, push the flag on wether this hash
    // will require a decommitment (False) or a previously computed hash (True). Also, if the
    // sibling of this child does not exist, the sibling must be to the "right" of the
    // "right-most" leaf, so the hash can be skipped in favor of just using the child itself.
    // Further, the parent of this node it itself relevant, in a subsequent iteration.
    if (relevant[i]) {
      flags.push(left === right);
      skips.push(!sibling);
      orders.push(left);
      relevant[i >>> 1] = true;
    }

    known[i] = left || right;
  }

  return {
    decommitments: decommitments.filter((d) => d).map(Buffer.from),
    flags,
    skips,
    orders: !sortedHash ? orders : undefined,
  };
};

// Convert the flags, skips, and orders generated by generateBooleans into a 32-byte bit-set
const generateBits = ({ tree, indices }, options = {}) => {
  const { decommitments, flags, orders, skips } = generateBooleans({ tree, indices }, options);

  assert(flags.length <= 255, 'Proof too large for bit flags.');

  const stopMask = leftShift(to32ByteBuffer(1), flags.length);
  const proof = orders ? [to32ByteBoolBuffer(orders)].concat(decommitments) : decommitments;
  const flagsAsBits = or(to32ByteBoolBuffer(flags), stopMask);
  const skipsAsBits = or(to32ByteBoolBuffer(skips), stopMask);

  return { compactProof: [flagsAsBits, skipsAsBits].concat(proof) };
};

const generate = (parameters, options = {}) => {
  return options.compact ? generateBits(parameters, options) : generateBooleans(parameters, options);
};

// This is the MultiIndexedProof.getRoot algorithm, slightly simplified to take into account that
// this is to be used with a hash function that sorts the material it hashes, and thus this uses flags
// to determine hashing content, instead of the indices. Further, this implements skipping hashing for
// nodes without siblings to the "right", in the case of unbalanced trees.
// See MultiIndexedProof.getRoot for relevant inline comments.
const getRootBooleans = ({ leafs, flags, skips, orders, decommitments }, options = {}) => {
  const { hashFunction = hashNode } = options;
  const hashCount = flags.length;
  const leafCount = leafs.length;
  const hashes = leafs.map((leaf) => leaf).reverse();

  let readIndex = 0;
  let writeIndex = 0;
  let decommitmentIndex = 0;

  for (let i = 0; i < hashCount; i++) {
    if (skips[i]) {
      hashes[writeIndex++] = hashes[readIndex++];

      readIndex %= leafCount;
      writeIndex %= leafCount;
      continue;
    }

    const right = flags[i] ? hashes[readIndex++] : decommitments[decommitmentIndex++];
    readIndex %= leafCount;
    const left = hashes[readIndex++];
    hashes[writeIndex++] = orders?.[i] ? hashFunction(left, right) : hashFunction(right, left);

    readIndex %= leafCount;
    writeIndex %= leafCount;
  }

  const rootIndex = (writeIndex === 0 ? leafCount : writeIndex) - 1;

  return { root: Buffer.from(hashes[rootIndex]) };
};

// This is identical to the above getRootBooleans algorithm, differing only in that the
// the flag and skip bit-set is shifted and checked, rather than boolean arrays.
// See getRootBooleans for relevant inline comments.
const getRootBits = ({ leafs, compactProof }, options = {}) => {
  const { hashFunction = hashNode, sortedHash = true } = options;
  const flags = compactProof[0];
  const skips = compactProof[1];
  const orders = sortedHash ? undefined : compactProof[2];
  const decommitments = compactProof.slice(sortedHash ? 2 : 3);
  const leafCount = leafs.length;
  const hashes = leafs.map((leaf) => leaf).reverse();

  let readIndex = 0;
  let writeIndex = 0;
  let decommitmentIndex = 0;
  let bitCheck = Buffer.from('0000000000000000000000000000000000000000000000000000000000000001', 'hex');

  while (true) {
    const flag = and(flags, bitCheck).equals(bitCheck);

    if (and(skips, bitCheck).equals(bitCheck)) {
      if (flag) {
        const rootIndex = (writeIndex === 0 ? leafCount : writeIndex) - 1;

        return { root: hashes[rootIndex] };
      }

      hashes[writeIndex++] = hashes[readIndex++];

      readIndex %= leafCount;
      writeIndex %= leafCount;
      bitCheck = leftShift(bitCheck, 1);
      continue;
    }

    const right = flag ? hashes[readIndex++] : decommitments[decommitmentIndex++];
    readIndex %= leafCount;
    const left = hashes[readIndex++];

    const order = orders && and(orders, bitCheck).equals(bitCheck);
    hashes[writeIndex++] = order ? hashFunction(left, right) : hashFunction(right, left);

    readIndex %= leafCount;
    writeIndex %= leafCount;
    bitCheck = leftShift(bitCheck, 1);
  }
};

const getRoot = (parameters, options = {}) => {
  return parameters.compactProof ? getRootBits(parameters, options) : getRootBooleans(parameters, options);
};

// This is identical to the above getRootBooleans algorithm, differing only in that the
// new root (due to the updated leafs), is computed along the way.
// See getRootBooleans for relevant inline comments.
const getNewRootBooleans = ({ leafs, newLeafs, flags, skips, orders, decommitments }, options = {}) => {
  const { hashFunction = hashNode } = options;
  const hashCount = flags.length;
  const leafCount = leafs.length;
  const hashes = leafs.map((leaf) => leaf).reverse();
  const newHashes = newLeafs.map((leaf) => leaf).reverse();

  let readIndex = 0;
  let writeIndex = 0;
  let decommitmentIndex = 0;

  for (let i = 0; i < hashCount; i++) {
    if (skips[i]) {
      hashes[writeIndex] = hashes[readIndex];
      newHashes[writeIndex++] = newHashes[readIndex++];

      readIndex %= leafCount;
      writeIndex %= leafCount;
      continue;
    }

    const right = flags[i] ? hashes[readIndex] : decommitments[decommitmentIndex];
    const newRight = flags[i] ? newHashes[readIndex++] : decommitments[decommitmentIndex++];
    readIndex %= leafCount;

    const left = hashes[readIndex];
    const newLeft = newHashes[readIndex++];
    hashes[writeIndex] = orders?.[i] ? hashFunction(left, right) : hashFunction(right, left);
    newHashes[writeIndex++] = orders?.[i] ? hashFunction(newLeft, newRight) : hashFunction(newRight, newLeft);

    readIndex %= leafCount;
    writeIndex %= leafCount;
  }

  const rootIndex = (writeIndex === 0 ? leafCount : writeIndex) - 1;

  return {
    root: Buffer.from(hashes[rootIndex]),
    newRoot: Buffer.from(newHashes[rootIndex]),
  };
};

// This is identical to the above getRootBits algorithm, differing only in that the
// new root (due to the updated leafs), is computed along the way.
// See getRootBits for relevant inline comments.
const getNewRootBits = ({ leafs, newLeafs, compactProof }, options = {}) => {
  const { hashFunction = hashNode, sortedHash = true } = options;
  const flags = compactProof[0];
  const skips = compactProof[1];
  const orders = sortedHash ? undefined : compactProof[2];
  const decommitments = compactProof.slice(sortedHash ? 2 : 3);
  const leafCount = leafs.length;
  const hashes = leafs.map((leaf) => leaf).reverse();
  const newHashes = newLeafs.map((leaf) => leaf).reverse();

  let readIndex = 0;
  let writeIndex = 0;
  let decommitmentIndex = 0;
  let bitCheck = Buffer.from('0000000000000000000000000000000000000000000000000000000000000001', 'hex');

  while (true) {
    const flag = and(flags, bitCheck).equals(bitCheck);

    if (and(skips, bitCheck).equals(bitCheck)) {
      if (flag) {
        const rootIndex = (writeIndex === 0 ? leafCount : writeIndex) - 1;

        return {
          root: Buffer.from(hashes[rootIndex]),
          newRoot: Buffer.from(newHashes[rootIndex]),
        };
      }

      hashes[writeIndex] = hashes[readIndex];
      newHashes[writeIndex++] = newHashes[readIndex++];

      readIndex %= leafCount;
      writeIndex %= leafCount;
      bitCheck = leftShift(bitCheck, 1);
      continue;
    }

    const right = flag ? hashes[readIndex] : decommitments[decommitmentIndex];
    const newRight = flag ? newHashes[readIndex++] : decommitments[decommitmentIndex++];
    readIndex %= leafCount;

    const left = hashes[readIndex];
    const newLeft = newHashes[readIndex++];

    const order = orders && and(orders, bitCheck).equals(bitCheck);
    hashes[writeIndex] = order ? hashFunction(left, right) : hashFunction(right, left);
    newHashes[writeIndex++] = order ? hashFunction(newLeft, newRight) : hashFunction(newRight, newLeft);

    readIndex %= leafCount;
    writeIndex %= leafCount;
    bitCheck = leftShift(bitCheck, 1);
  }
};

const getNewRoot = (parameters, options = {}) => {
  return parameters.compactProof ? getNewRootBits(parameters, options) : getNewRootBooleans(parameters, options);
};

const getIndicesWithBooleans = ({ leafCount, flags, skips, orders }) => {
  assert(orders, 'Cannot infer indices without orders in proof.');

  const hashCount = flags.length;
  const indices = Array(leafCount).fill(0);
  const groupedWithNext = Array(leafCount).fill(false);
  const bitsPushed = Array(leafCount).fill(0);
  let leafIndex = 0;

  for (let i = 0; i < hashCount; i++) {
    if (skips[i]) {
      while (true) {
        bitsPushed[leafIndex]++;

        if (!groupedWithNext[leafIndex++]) break;
      }

      leafIndex %= leafCount;
      continue;
    }

    if (flags[i]) {
      while (true) {
        if (orders[i]) indices[leafIndex] |= 1 << bitsPushed[leafIndex];

        bitsPushed[leafIndex]++;

        if (!groupedWithNext[leafIndex]) {
          groupedWithNext[leafIndex++] = true;
          break;
        }

        groupedWithNext[leafIndex++] = true;
      }
    }

    while (true) {
      if (!orders[i]) indices[leafIndex] |= 1 << bitsPushed[leafIndex];

      bitsPushed[leafIndex]++;

      if (!groupedWithNext[leafIndex++]) break;
    }

    leafIndex %= leafCount;
  }

  return { indices: indices.reverse() };
};

const getIndicesWithBits = ({
  leafCount,
  compactProof,
  flags = compactProof[0],
  skips = compactProof[1],
  orders = compactProof[2],
}) => {
  const indices = Array(leafCount).fill(0);
  const groupedWithNext = Array(leafCount).fill(false);
  const bitsPushed = Array(leafCount).fill(0);
  let leafIndex = 0;
  let bitCheck = Buffer.from('0000000000000000000000000000000000000000000000000000000000000001', 'hex');

  while (true) {
    const flag = and(flags, bitCheck).equals(bitCheck);

    if (and(skips, bitCheck).equals(bitCheck)) {
      if (flag) return { indices: indices.reverse() };

      while (true) {
        bitsPushed[leafIndex]++;

        if (!groupedWithNext[leafIndex++]) break;
      }

      leafIndex %= leafCount;
      bitCheck = leftShift(bitCheck, 1);
      continue;
    }

    const order = and(orders, bitCheck).equals(bitCheck);

    if (flag) {
      while (true) {
        if (order) indices[leafIndex] |= 1 << bitsPushed[leafIndex];

        bitsPushed[leafIndex]++;

        if (!groupedWithNext[leafIndex]) {
          groupedWithNext[leafIndex++] = true;
          break;
        }

        groupedWithNext[leafIndex++] = true;
      }
    }

    while (true) {
      if (!order) indices[leafIndex] |= 1 << bitsPushed[leafIndex];

      bitsPushed[leafIndex]++;

      if (!groupedWithNext[leafIndex++]) break;
    }

    leafIndex %= leafCount;
    bitCheck = leftShift(bitCheck, 1);
  }
};

const getIndices = (parameters, options = {}) => {
  return parameters.compactProof
    ? getIndicesWithBits(parameters, options)
    : getIndicesWithBooleans(parameters, options);
};

module.exports = { generate, getRoot, getNewRoot, getIndices };
